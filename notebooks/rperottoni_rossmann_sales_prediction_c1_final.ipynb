{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afe3555",
   "metadata": {},
   "source": [
    "# ROSSMANN SALES PREDICTION - FIRST CYCLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f554598",
   "metadata": {},
   "source": [
    "# 0.0 - IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c034c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:09:55.309418Z",
     "start_time": "2023-06-12T19:09:53.065116Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import requests\n",
    "import datetime\n",
    "import warnings\n",
    "import inflection\n",
    "\n",
    "import numpy       as np\n",
    "import pandas      as pd\n",
    "import seaborn     as sns\n",
    "import xgboost     as xgb\n",
    "\n",
    "from pandas_profiling        import ProfileReport\n",
    "from IPython.core.display    import HTML\n",
    "from IPython.display         import Image\n",
    "from boruta                  import BorutaPy\n",
    "from scipy                   import stats           as ss\n",
    "from matplotlib              import pyplot          as plt\n",
    "from sklearn                 import model_selection as ms\n",
    "\n",
    "from sklearn.ensemble        import RandomForestRegressor\n",
    "from sklearn.linear_model    import LinearRegression, Lasso\n",
    "from sklearn.preprocessing   import MinMaxScaler, LabelEncoder, RobustScaler\n",
    "from sklearn.metrics         import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "warnings.filterwarnings( 'ignore' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5970e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:09:56.276229Z",
     "start_time": "2023-06-12T19:09:56.259647Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' %x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8417cad0",
   "metadata": {},
   "source": [
    "## 0.1 Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5512dcc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:09:58.206975Z",
     "start_time": "2023-06-12T19:09:58.136155Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_validation(x_training, kfold, model_name, model, verbose=False ):\n",
    "    mae_list= []\n",
    "    mape_list = []\n",
    "    rmse_list = []\n",
    "\n",
    "    for k in reversed( range(1, kfold+1 ) ):\n",
    "        if verbose:\n",
    "            print('\\nKFold Number: {}'.format(k) )\n",
    "       \n",
    "        # start and end date for validation\n",
    "        validation_start_date = x_training['date'].max() - datetime.timedelta( days=k*6*7 )\n",
    "        validadtion_end_date = x_training['date'].max() - datetime.timedelta( days=(k-1)*6*7 )\n",
    "\n",
    "        # filtering dataset\n",
    "        training = x_training[x_training['date'] < validation_start_date]\n",
    "        validation = x_training[(x_training['date'] >= validation_start_date) & (x_training['date'] <= validadtion_end_date)]\n",
    "\n",
    "        # training and validation datasel\n",
    "        # training\n",
    "        xtraining = training.drop( ['date','sales'], axis=1 )\n",
    "        ytraining = training['sales']\n",
    "\n",
    "        # validation\n",
    "        xvalidation = validation.drop( ['date','sales'], axis=1 )\n",
    "        yvalidation = validation['sales']\n",
    "\n",
    "        # model\n",
    "        m = model.fit( xtraining, ytraining )\n",
    "\n",
    "        #prediction\n",
    "        yhat = m.predict( xvalidation )\n",
    "\n",
    "        #performance\n",
    "        m_result = ml_error( model_name, ( yvalidation), (yhat) )\n",
    "\n",
    "        # store performance of each kfold interation\n",
    "        mae_list.append( m_result['MAE'] )\n",
    "        mape_list.append( m_result['MAPE'] )\n",
    "        rmse_list.append( m_result['RMSE'] )\n",
    "\n",
    "    return pd.DataFrame( {'Model Name': model_name,\n",
    "                          'MAE CV': np.round( np.mean( mae_list), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mae_list ), 2 ).astype( str ),\n",
    "                          'MAPE CV': np.round( np.mean( mape_list), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mape_list ), 2 ).astype( str ),\n",
    "                          'RMSE CV': np.round( np.mean( rmse_list), 2 ).astype( str ) + ' +/- ' + np.round( np.std( rmse_list ), 2 ).astype( str ) }, index=[0] )\n",
    "\n",
    "def ml_error( model_name, y, yhat ):\n",
    "    mae = mean_absolute_error( y, yhat )\n",
    "    mape = mean_absolute_percentage_error( y, yhat )\n",
    "    rmse = np.sqrt( mean_squared_error( y, yhat ) )\n",
    "    \n",
    "    return pd.DataFrame( {'Model Name': model_name,\n",
    "                          'MAE': mae,\n",
    "                          'MAPE': mape,\n",
    "                          'RMSE': rmse}, index=[0])\n",
    "\n",
    "def mean_percentage_error ( y, yhat ):\n",
    "    return np.mean( ( y- yhat ) /y )\n",
    "\n",
    "def cramer_v( x, y):\n",
    "    cm = pd.crosstab( x, y).values   \n",
    "    n = cm.sum()\n",
    "    r, k = cm.shape    \n",
    "    \n",
    "    chi2 = ss.chi2_contingency( cm )[0]\n",
    "    chi2corr = max( 0, chi2 - (k-1)*(r-1)/(n-1) )\n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    rcorr = r - (r-1)**2/(n-1) \n",
    "    \n",
    "    return np.sqrt( (chi2corr/n) / ( min( kcorr-1, rcorr-1 ) ) )\n",
    "\n",
    "def data_preparation (df_prep):\n",
    "    rs = RobustScaler()\n",
    "    mms = MinMaxScaler()\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    \n",
    "# Data Filtering\n",
    "    df_prep = df_prep[ (df_prep['open'] != 0) & (df_prep['sales'] > 0) ]\n",
    "    \n",
    "# Change DTypes\n",
    "    df_prep['date'] = pd.to_datetime (df_prep['date'] )\n",
    "       \n",
    "# Fill NA Values\n",
    "    # Competition Distance\n",
    "    df_prep['competition_distance'] = df_prep['competition_distance'].apply( lambda x: 200000.0 if math.isnan( x ) else x )\n",
    "\n",
    "    # Competition Open Since Month\n",
    "    df_prep['competition_open_since_month'] = df_prep.apply( lambda x: x['date'].month if math.isnan( x['competition_open_since_month'] ) else x['competition_open_since_month'], axis=1 )\n",
    "\n",
    "    # Competition Open Since Year\n",
    "    df_prep['competition_open_since_year'] = df_prep.apply( lambda x: x['date'].year if math.isnan( x['competition_open_since_year'] ) else x['competition_open_since_year'], axis=1 )\n",
    "\n",
    "    # Promo2 Since Week\n",
    "    df_prep['promo2_since_week'] = df_prep.apply( lambda x: x['date'].week if math.isnan( x['promo2_since_week'] ) else x['promo2_since_week'], axis=1 )\n",
    "\n",
    "    # Promo2 Since Year\n",
    "    df_prep['promo2_since_year'] = df_prep.apply( lambda x: x['date'].year if math.isnan( x['promo2_since_year'] ) else x['promo2_since_year'], axis=1 )\n",
    "\n",
    "    # Promo Interval\n",
    "    month_map = {1: 'Jan', 2: 'Fev', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sept', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "\n",
    "    df_prep['promo_interval'].fillna(0, inplace=True)\n",
    "\n",
    "    df_prep['month_map'] = df_prep['date'].dt.month.map( month_map )\n",
    "\n",
    "    df_prep['is_promo'] = df_prep[['promo_interval', 'month_map']].apply( lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split( ',' ) else 0, axis=1 )\n",
    "    \n",
    "\n",
    "# Change Dtypes after Fill NA\n",
    "    df_prep['competition_open_since_month'] = df_prep['competition_open_since_month'].astype( int )\n",
    "    df_prep['competition_open_since_year'] = df_prep['competition_open_since_year'].astype( int )\n",
    "    df_prep['promo2_since_week'] = df_prep['promo2_since_week'].astype( int )\n",
    "    df_prep['promo2_since_year'] = df_prep['promo2_since_year'].astype( int )\n",
    "    \n",
    "    \n",
    "# Feature Engineering\n",
    "    # year\n",
    "    df_prep['year'] = df_prep['date'].dt.year\n",
    "\n",
    "    # month\n",
    "    df_prep['month'] = df_prep['date'].dt.month\n",
    "\n",
    "    # day\n",
    "    df_prep['day'] = df_prep['date'].dt.day\n",
    "\n",
    "    # week of year\n",
    "    df_prep['week_of_year'] = df_prep['date'].dt.weekofyear\n",
    "\n",
    "    # year week\n",
    "    df_prep['year_week'] = df_prep['date'].dt.strftime( '%Y-%W' )\n",
    "\n",
    "    # competition since\n",
    "    df_prep['competition_since'] = df_prep.apply( lambda x: datetime.datetime( year=x['competition_open_since_year'], month=x['competition_open_since_month'], day=1 ), axis=1 )\n",
    "    df_prep['competition_time_month'] = ( ( df_prep['date'] - df_prep['competition_since'] ) / 30 ).apply( lambda x: x.days ).astype( int )                                                                                      \n",
    "\n",
    "    # promo since\n",
    "    df_prep['promo_since'] = df_prep['promo2_since_year'].astype( str ) + '-' + df_prep['promo2_since_week'].astype( str )\n",
    "    df_prep['promo_since'] = df_prep['promo_since'].apply( lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
    "    df_prep['promo_time_week'] = ( ( df_prep['date'] - df_prep['promo_since'] ) /7 ).apply( lambda x: x.days ).astype( int )\n",
    "\n",
    "    # assortment\n",
    "    df_prep['assortment'] = df_prep['assortment'].apply(lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended' )\n",
    "\n",
    "    # state holiday\n",
    "    df_prep['state_holiday'] = df_prep['state_holiday'].apply( lambda x:'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day' )\n",
    "\n",
    "    \n",
    "# Data Filtering\n",
    "    df_prep = df_prep[ (df_prep['open'] != 0) & (df_prep['sales'] > 0) ]\n",
    "    cols_drop = ['customers', 'open', 'promo_interval', 'month_map']\n",
    "    df_prep = df_prep.drop( cols_drop, axis = 1)\n",
    "    \n",
    "    \n",
    "# Reescaling\n",
    "    # Year\n",
    "    df_prep['year'] = mms.fit_transform( df_prep[['year']].values )\n",
    "\n",
    "    # competition distance\n",
    "    df_prep['competition_distance'] = rs.fit_transform( df_prep[['competition_distance']].values )\n",
    "\n",
    "    # competition time month\n",
    "    df_prep['competition_time_month'] = rs.fit_transform( df_prep[['competition_time_month']].values )\n",
    "\n",
    "    # promo time week\n",
    "    df_prep['promo_time_week'] = mms.fit_transform( df_prep[['promo_time_week']].values )\n",
    "\n",
    "\n",
    "# Transformation\n",
    "    # day of week\n",
    "    df_prep['day_of_week_sin'] = df_prep['day_of_week'].apply( lambda x: np.sin( x * ( 2. * np.pi/7 ) ) )\n",
    "    df_prep['day_of_week_cos'] = df_prep['day_of_week'].apply( lambda x: np.sin( x * ( 2. * np.pi/7 ) ) )\n",
    "\n",
    "    # month\n",
    "    df_prep['month_sin'] = df_prep['month'].apply( lambda x: np.sin( x * ( 2. * np.pi/12 ) ) )\n",
    "    df_prep['month_cos'] = df_prep['month'].apply( lambda x: np.sin( x * ( 2. * np.pi/12 ) ) )\n",
    "\n",
    "    # day\n",
    "    df_prep['day_sin'] = df_prep['day'].apply( lambda x: np.sin( x * ( 2. * np.pi/30 ) ) )\n",
    "    df_prep['day_cos'] = df_prep['day'].apply( lambda x: np.sin( x * ( 2. * np.pi/30 ) ) )\n",
    "\n",
    "    # week of year\n",
    "    df_prep['week_of_year_sin'] = df_prep['week_of_year'].apply( lambda x: np.sin( x * ( 2. * np.pi/52 ) ) )\n",
    "    df_prep['week_of_year_cos'] = df_prep['week_of_year'].apply( lambda x: np.sin( x * ( 2. * np.pi/52 ) ) )\n",
    "\n",
    "    \n",
    "# Encoder\n",
    "    # state_holiday - Hot Encoding\n",
    "    df_prep = pd.get_dummies( df_prep, prefix=['state_holiday'], columns=['state_holiday'] )\n",
    "\n",
    "    # store_type - Label Encoding\n",
    "    le = LabelEncoder()\n",
    "    df_prep['store_type'] = le.fit_transform( df_prep['store_type'] )\n",
    "\n",
    "    # assortment - Ordinal Encoding\n",
    "    assortment_dict={'basic':1, 'extra':2, 'extended':3 }\n",
    "    df_prep['assortment'] = df_prep['assortment'].map( assortment_dict )\n",
    "    \n",
    "    # Feature Selection\n",
    "    cols_selected = ['store', 'promo', 'month_cos', 'month_sin', 'store_type', 'assortment', 'competition_distance', 'competition_open_since_month', 'competition_open_since_year',  'promo2',  'promo2_since_week',\n",
    "                     'promo2_since_year', 'competition_time_month', 'promo_time_week', 'day_of_week_sin', 'day_of_week_cos', 'week_of_year_cos', 'week_of_year_sin', 'day_sin', 'day_cos', 'sales', 'date']\n",
    "    \n",
    "    return( df_prep[cols_selected] )  \n",
    "\n",
    "\n",
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    \n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [25,12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    \n",
    "    display( HTML( '<style>.container {width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "    \n",
    "    sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ad9f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:58:03.866158Z",
     "start_time": "2023-06-12T18:58:03.836767Z"
    }
   },
   "outputs": [],
   "source": [
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa38595",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "## 0.2 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd944e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:10:03.214190Z",
     "start_time": "2023-06-12T19:10:02.228820Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sales_raw = pd.read_csv( 'C:/Users/perot/Documents/ds_repos/projects/Rossmann_Sales_Prediction/data_csv/train.csv', low_memory= False)\n",
    "df_store_raw = pd.read_csv( 'C:/Users/perot/Documents/ds_repos/projects/Rossmann_Sales_Prediction/data_csv/store.csv', low_memory= False)\n",
    "\n",
    "# Merge\n",
    "df_raw = pd.merge( df_sales_raw, df_store_raw, how='left', on='Store' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9143f3b2",
   "metadata": {},
   "source": [
    "## 0.3 - Rename Colunms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403097fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:10:05.330467Z",
     "start_time": "2023-06-12T19:10:05.311759Z"
    }
   },
   "outputs": [],
   "source": [
    "## rename Columns\n",
    "cols_old = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'StoreType',\n",
    "            'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2',\n",
    "            'Promo2SinceWeek','Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "snakecase = lambda x: inflection.underscore( x )\n",
    "\n",
    "cols_new = list( map( snakecase, cols_old ) )\n",
    "\n",
    "# rename\n",
    "df_raw.columns = cols_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0be817",
   "metadata": {},
   "source": [
    "## 0.4 - SPLIT DATASET INTO TRAINING, TEST AND VALIDATION DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2880f458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:10:08.092818Z",
     "start_time": "2023-06-12T19:10:07.414436Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying train test split to create Train, Validation and Test datasets\n",
    "\n",
    "X = df_raw.drop( 'sales', axis=1 )\n",
    "y = df_raw['sales'].copy()\n",
    "x_train, x_valid, y_train, y_valid = ms.train_test_split( X, y, test_size=0.15 )\n",
    "x_train, x_test, y_train, y_test = ms.train_test_split( x_train, y_train, test_size=0.15, shuffle=True, random_state=None )\n",
    "\n",
    "print(f\" x_train: {x_train.shape}\\n y_train: {y_train.shape}\\n x_valid: {x_valid.shape}\\n y_valid: {y_valid.shape}\\n x_test: {x_test.shape}\\n y_test: {y_test.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d498462c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1.0 STEP 1 - DATA DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b59be8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:58:07.585971Z",
     "start_time": "2023-06-12T18:58:07.521470Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1_train = pd.concat([x_train, y_train], axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b874b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:58:07.976523Z",
     "start_time": "2023-06-12T18:58:07.870367Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1 = df1_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3205e63",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.1 Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee459fc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:58:30.043997Z",
     "start_time": "2023-06-12T18:58:30.038979Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print( 'Number of Rows: {}'.format( df1.shape[0] ) )\n",
    "print( 'Number of Cols: {}'.format( df1.shape[1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4550cd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.3 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fa760f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:58:30.856082Z",
     "start_time": "2023-06-12T18:58:30.557753Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1['date'] = pd.to_datetime (df1['date'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb0a61",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.4 Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90477e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:58:31.369856Z",
     "start_time": "2023-06-12T18:58:31.035851Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d6a3b2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.5 Fillout NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a853bd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:58:58.763759Z",
     "start_time": "2023-06-12T18:58:31.495413Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Competition Distance: to indicate that there is no competitor, a distance of 200.000m will be imputed\n",
    "df1['competition_distance'] = df1['competition_distance'].apply( lambda x: 200000.0 if math.isnan( x ) else x )\n",
    "\n",
    "# Competition Open Since Month: to fill this data, were selected the month from the column date, just to not be a NA value.\n",
    "df1['competition_open_since_month'] = df1.apply( lambda x: x['date'].month if math.isnan( x['competition_open_since_month'] ) else x['competition_open_since_month'], axis=1 )\n",
    "\n",
    "# Competition Open Since Year to fill this data, were selected the year from the column date, just to not be a NA value.\n",
    "df1['competition_open_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['competition_open_since_year'] ) else x['competition_open_since_year'], axis=1 )\n",
    "\n",
    "# Promo2 Since Week to fill this data, were selected the week from the column date, just to not be a NA value.\n",
    "df1['promo2_since_week'] = df1.apply( lambda x: x['date'].week if math.isnan( x['promo2_since_week'] ) else x['promo2_since_week'], axis=1 )\n",
    "\n",
    "# Promo2 Since Year to fill this data, were selected the year from the column date, just to not be a NA value.\n",
    "df1['promo2_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['promo2_since_year'] ) else x['promo2_since_year'], axis=1 )\n",
    "\n",
    "# Promo Interval\n",
    "month_map = {1: 'Jan', 2: 'Fev', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sept', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "\n",
    "df1['promo_interval'].fillna(0, inplace=True)\n",
    "\n",
    "df1['month_map'] = df1['date'].dt.month.map( month_map )\n",
    "\n",
    "df1['is_promo'] = df1[['promo_interval', 'month_map']].apply( lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split( ',' ) else 0, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5490b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:58:59.139711Z",
     "start_time": "2023-06-12T18:58:58.767737Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a144bfc6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.6 Change Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b63afe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:58:59.186446Z",
     "start_time": "2023-06-12T18:58:59.140695Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1['competition_open_since_month'] = df1['competition_open_since_month'].astype( int )\n",
    "df1['competition_open_since_year'] = df1['competition_open_since_year'].astype( int )\n",
    "\n",
    "df1['promo2_since_week'] = df1['promo2_since_week'].astype( int )\n",
    "df1['promo2_since_year'] = df1['promo2_since_year'].astype( int )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39f079a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.7 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e78ee2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:59:49.825904Z",
     "start_time": "2023-06-12T18:58:59.190096Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prof = ProfileReport(df1)\n",
    "prof.to_file(output_file='data_descriptive.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff90c41c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 1.7.1 Numerical Categorics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028218e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:59:49.872266Z",
     "start_time": "2023-06-12T18:59:49.827912Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_attributes = df1.select_dtypes( include=['int32', 'int64', 'float64'] )\n",
    "cat_attributes = df1.select_dtypes( exclude=['int32', 'int64', 'float64', 'datetime64[ns]'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b13e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:59:51.319208Z",
     "start_time": "2023-06-12T18:59:49.875154Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Central Tendency - mean, median\n",
    "ct1 = pd.DataFrame( num_attributes.apply( np.mean ) ).T\n",
    "ct2 = pd.DataFrame( num_attributes.apply( np.median ) ).T\n",
    "\n",
    "# Dispersion - std, min, max, range, skew, kurtosis\n",
    "d1 = pd.DataFrame( num_attributes.apply( np.std ) ).T\n",
    "d2 = pd.DataFrame( num_attributes.apply( min ) ).T\n",
    "d3 = pd.DataFrame( num_attributes.apply( max ) ).T\n",
    "d4 = pd.DataFrame( num_attributes.apply( lambda x: x.max() - x.min() ) ).T\n",
    "d5 = pd.DataFrame( num_attributes.apply( lambda x: x.skew() ) ).T\n",
    "d6 = pd.DataFrame( num_attributes.apply( lambda x: x.kurtosis() ) ).T\n",
    "\n",
    "# Concatenar\n",
    "m = pd.concat( [ d2, d3, d4, ct1, ct2, d1, d5, d6 ] ).T.reset_index()\n",
    "m.columns = ['attributes', 'min', 'max', 'range', 'mean', 'median', 'std', 'skew', 'kurtosis']\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9bf569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:59:53.163767Z",
     "start_time": "2023-06-12T18:59:51.321095Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.displot( df1['competition_distance'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b5e84b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 1.7.2 Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b123b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:59:53.289731Z",
     "start_time": "2023-06-12T18:59:53.165281Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat_attributes.apply( lambda x: x.unique().shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44990191",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:59:53.775511Z",
     "start_time": "2023-06-12T18:59:53.293623Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux1 = df1[(df1['state_holiday'] != '0') & (df1['sales'] > 0)]\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.boxplot( x='state_holiday', y='sales', data=aux1 )\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.boxplot( x='store_type', y='sales', data=aux1 )\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.boxplot( x='assortment', y='sales', data=aux1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15811f4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2.0 STEP 2 - FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e62cabc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:59:53.822474Z",
     "start_time": "2023-06-12T18:59:53.778749Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaa2622",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.1 Mapa mental de Hipoteses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ae94e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T18:59:53.854541Z",
     "start_time": "2023-06-12T18:59:53.825324Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Image('C:/Users/perot/Documents/ds_repos/projects/Rossmann_Sales_Prediction/img/mindmaphypothesis.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1d95b0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.2 Hypothesis Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa130c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 2.2.1 Hypothesis related to the Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a34c5a7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**1.** Stores with a higher number of employees should sell more.\n",
    "\n",
    "**2.** Stores with a larger inventory capacity should sell more.\n",
    "\n",
    "**3.** Larger-sized stores should sell more.\n",
    "\n",
    "**4.** Stores with a greater variety of products should sell more.\n",
    "\n",
    "**5.** Stores located closer to competitors should sell less.\n",
    "\n",
    "**6.** Stores with longer-standing competitors should sell more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10255e94",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 2.2.2 Hypothesis related to the Product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8bfb7d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**1.** Stores that invest more in marketing should sell more.\n",
    "\n",
    "**2.** Stores with greater product exposure should sell more.\n",
    "\n",
    "**3.** Stores with lower-priced products should sell more.\n",
    "\n",
    "**4.** Stores with more aggressive promotions (larger discounts) should sell more.\n",
    "\n",
    "**5.** Stores with promotions active for a longer period of time should sell more.\n",
    "\n",
    "**6.** Stores with more days of promotion should sell more.\n",
    "\n",
    "**7.** Stores with more consecutive promotions should sell more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcf455c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 2.2.3 Hipoteses Tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8335692d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**1.** Stores open during the Christmas holiday should sell more.\n",
    "\n",
    "**2.** Stores should sell more over the years.\n",
    "\n",
    "**3.** Stores should sell more in the second half of the year.\n",
    "\n",
    "**4.** Stores should sell more after the 10th day of each month.\n",
    "\n",
    "**5.** Stores should sell less on weekends.\n",
    "\n",
    "**6.** Stores should sell less during school holidays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73690e75",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 2.2.4 Lista Final de Hipoteses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c6e353",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**1.** Stores with a larger variety of products should sell more.\n",
    "\n",
    "**2.** Stores with closer competitors should sell less.\n",
    "\n",
    "**3.** Stores with longer-standing competitors should sell more.\n",
    "\n",
    "**4.** Stores with promotions active for a longer period of time should sell more.\n",
    "\n",
    "**5.** Stores with more days of promotion should sell more.\n",
    "\n",
    "**7.** Stores with more consecutive promotions should sell more.\n",
    "\n",
    "**8.** Stores open during the Christmas holiday should sell more.\n",
    "\n",
    "**9.** Stores should sell more over the years.\n",
    "\n",
    "**10.** Stores should sell more in the second half of the year.\n",
    "\n",
    "**11.** Stores should sell more after the 10th day of each month.\n",
    "\n",
    "**12.** Stores should sell less on weekends.\n",
    "\n",
    "**13.** Stores should sell less during school holidays.****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34faa176",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.3 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd67dc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:00:13.455488Z",
     "start_time": "2023-06-12T18:59:53.858048Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# year\n",
    "df2['year'] = df2['date'].dt.year\n",
    "\n",
    "# month\n",
    "df2['month'] = df2['date'].dt.month\n",
    "\n",
    "# day\n",
    "df2['day'] = df2['date'].dt.day\n",
    "\n",
    "# week of year\n",
    "df2['week_of_year'] = df2['date'].dt.weekofyear\n",
    "\n",
    "# year week\n",
    "df2['year_week'] = df2['date'].dt.strftime( '%Y-%W' )\n",
    "\n",
    "# competition since\n",
    "df2['competition_since'] = df2.apply( lambda x: datetime.datetime( year=x['competition_open_since_year'], month=x['competition_open_since_month'], day=1 ), axis=1 )\n",
    "df2['competition_time_month'] = ( ( df2['date'] - df2['competition_since'] ) / 30 ).apply( lambda x: x.days ).astype( int )                                                                                      \n",
    "\n",
    "# promo since\n",
    "df2['promo_since'] = df2['promo2_since_year'].astype( str ) + '-' + df2['promo2_since_week'].astype( str )\n",
    "df2['promo_since'] = df2['promo_since'].apply( lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
    "df2['promo_time_week'] = ( ( df2['date'] - df2['promo_since'] ) /7 ).apply( lambda x: x.days ).astype( int )\n",
    "\n",
    "# assortment\n",
    "df2['assortment'] = df2['assortment'].apply(lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended' )\n",
    "\n",
    "# state holiday\n",
    "df2['state_holiday'] = df2['state_holiday'].apply( lambda x:'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bcc249",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3.0 STEP 3 - FEATURE FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e171852b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:00:13.593812Z",
     "start_time": "2023-06-12T19:00:13.456503Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96f09f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:00:13.623672Z",
     "start_time": "2023-06-12T19:00:13.598902Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee18840",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.1 Filtragem das Linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d905220",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:00:13.718290Z",
     "start_time": "2023-06-12T19:00:13.626568Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3 = df3[ (df3['open'] != 0) & (df3['sales'] > 0) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7479a09a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.2 Seleção das Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaae20d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:00:13.797969Z",
     "start_time": "2023-06-12T19:00:13.721273Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols_drop = ['customers', 'open', 'promo_interval', 'month_map']\n",
    "df3 = df3.drop( cols_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee35f6ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:00:13.813400Z",
     "start_time": "2023-06-12T19:00:13.799872Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537a71c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 4.0 STEP 4 - EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c82c510",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:00:13.859836Z",
     "start_time": "2023-06-12T19:00:13.817489Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae113a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 4.1 Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fbcd36",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 4.1.1 Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013139db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:00:17.699371Z",
     "start_time": "2023-06-12T19:00:13.861038Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(df4['sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1350fb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 4.1.2 Numerical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069733d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:00:20.345153Z",
     "start_time": "2023-06-12T19:00:17.701381Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "num_attributes.hist( bins = 25 );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4617a0f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 4.1.3 Categorical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7219e5bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:00:20.375095Z",
     "start_time": "2023-06-12T19:00:20.347504Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df4['state_holiday'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a59cb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:00:28.980015Z",
     "start_time": "2023-06-12T19:00:20.377094Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# state holiday\n",
    "plt.subplot( 3, 2, 1 )\n",
    "a = df4[df4['state_holiday'] != 'regular_day']\n",
    "sns.countplot( x=a['state_holiday'] )\n",
    "\n",
    "plt.subplot( 3, 2, 2 )\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'public_holiday']['sales'], label='public_holiday', shade=True )\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'easter_holiday']['sales'], label='easter_holiday', shade=True )\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'christmas']['sales'], label='christmas', shade=True )\n",
    "\n",
    "# store type\n",
    "plt.subplot( 3, 2, 3 )\n",
    "sns.countplot( x=a['store_type'] )\n",
    "\n",
    "plt.subplot( 3, 2, 4 )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'a']['sales'], label='a', shade=True )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'b']['sales'], label='b', shade=True )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'c']['sales'], label='c', shade=True )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'd']['sales'], label='d', shade=True )\n",
    "\n",
    "# assortment\n",
    "plt.subplot( 3, 2, 5 )\n",
    "sns.countplot( x=a['assortment'] )\n",
    "\n",
    "plt.subplot( 3, 2, 6 )\n",
    "sns.kdeplot( df4[df4['assortment'] == 'extended']['sales'], label='extended', shade=True )\n",
    "sns.kdeplot( df4[df4['assortment'] == 'basic']['sales'], label='basic', shade=True )\n",
    "sns.kdeplot( df4[df4['assortment'] == 'extra']['sales'], label='extra', shade=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f252aadc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 4.2 Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f049dc9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### H1. Stores with a larger variety of products should sell more.\n",
    "**False Hypothesis**: Stores with a larger variety of products sell less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6dd173",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T20:43:54.723068Z",
     "start_time": "2023-06-06T20:43:53.872971Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['assortment', 'sales']].groupby( 'assortment' ).sum().reset_index()\n",
    "sns.barplot( x='assortment', y='sales', data=aux1 );\n",
    "aux2 = df4[['year_week', 'assortment', 'sales']].groupby(['year_week','assortment'] ).sum().reset_index()\n",
    "aux2.pivot( index='year_week', columns='assortment', values='sales' ).plot()\n",
    "aux3 = aux2[aux2['assortment'] == 'extra']\n",
    "aux3.pivot( index='year_week', columns='assortment', values='sales' ).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a87d716",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### H2. Stores with closer competitors should sell less.\n",
    "**False Hypothesis**: Stores with closer competitors sell more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0280e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T20:43:56.317970Z",
     "start_time": "2023-06-06T20:43:55.541973Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['competition_distance','sales']].groupby('competition_distance').sum().reset_index()\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.scatterplot( x='competition_distance', y='sales', data=aux1 )\n",
    "\n",
    "plt.subplot( 1, 3, 2)\n",
    "bins = list( np.arange(0, 20000, 1000) )\n",
    "aux1['competition_distance_binned'] = pd.cut( aux1['competition_distance'], bins=bins )\n",
    "aux2 = aux1[['competition_distance_binned','sales']].groupby('competition_distance_binned').sum().reset_index()\n",
    "sns.barplot( x='competition_distance_binned', y='sales', data=aux2);\n",
    "plt.xticks( rotation=90 )\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7629f16",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### H3. Stores with longer-standing competitors should sell more.\n",
    "**False Hypothesis**: Stores with longer-standing competitors sell less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f441671a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T20:43:58.744872Z",
     "start_time": "2023-06-06T20:43:56.319970Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "plt.subplot( 1, 3, 1)\n",
    "aux1 = df4[['competition_time_month','sales']].groupby( 'competition_time_month' ).sum().reset_index()\n",
    "aux2 = aux1[(aux1['competition_time_month'] < 120) & (aux1['competition_time_month'] != 0)]\n",
    "sns.barplot( x='competition_time_month', y='sales', data=aux2);\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( 1, 3, 2)\n",
    "sns.regplot( x='competition_time_month', y='sales', data=aux2);\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson'), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f916a811",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### H4. Stores with promotions active for a longer period of time should sell more.\n",
    "**False Hypothesis**: Stores with promotions active for a longer period of time sell less after a certain period of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06834663",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T20:44:02.744743Z",
     "start_time": "2023-06-06T20:43:58.746873Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['promo_time_week','sales']].groupby('promo_time_week').sum().reset_index()\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "aux2 = aux1[aux1['promo_time_week'] > 0 ] # promo extendida\n",
    "sns.barplot(x='promo_time_week', y='sales', data=aux2);\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "aux3 = aux1[aux1['promo_time_week'] < 0 ] # promo regular\n",
    "sns.barplot(x='promo_time_week', y='sales', data=aux3);\n",
    "plt.xticks( rotation=90 );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfee23b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###<s>H5. Lojas com mais dias de promoção deveriam vender mais.</s>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc042f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### H7. Stores with more consecutive promotions should sell more.\n",
    "**False Hypothesis**: Stores with consecutive promotions sell less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ece9ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T20:44:02.791747Z",
     "start_time": "2023-06-06T20:44:02.746760Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "df4[['promo','promo2','sales']].groupby(['promo','promo2']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a8bd31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T20:44:03.232785Z",
     "start_time": "2023-06-06T20:44:02.792782Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[( df4['promo'] == 1 ) & (df4['promo2'] == 1)][['year_week','sales']].groupby('year_week').sum().reset_index()\n",
    "ax = aux1.plot()\n",
    "\n",
    "aux2 = df4[( df4['promo'] == 1 ) & (df4['promo2'] == 0)][['year_week','sales']].groupby('year_week').sum().reset_index()\n",
    "aux2.plot( ax=ax )\n",
    "\n",
    "ax.legend(labels=['Tradicional e Extendida','Tradicional'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12f4b2b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### **H8.** Stores open during the Christmas holiday should sell more.\n",
    "**False Hypothesis**: Stores open during the Christmas holiday sell less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57485077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T20:44:03.581786Z",
     "start_time": "2023-06-06T20:44:03.237795Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "aux = df4[df4['state_holiday'] != 'regular_day']\n",
    "aux1 = aux[['state_holiday', 'sales']].groupby('state_holiday').sum().reset_index()\n",
    "sns.barplot( x='state_holiday', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "aux2 = aux[['year','state_holiday', 'sales']].groupby( ['year', 'state_holiday'] ).sum().reset_index()\n",
    "sns.barplot( x='year', y='sales', hue='state_holiday', data=aux2 );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fea0ff",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### **H9.** Stores should sell more over the years.\n",
    "**False Hypothesis**: Store sell less over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa0136d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T20:44:04.199788Z",
     "start_time": "2023-06-06T20:44:03.582784Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['year','sales']].groupby( 'year' ).sum().reset_index()\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.barplot(x='year', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.regplot(x='year', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.heatmap(aux1.corr( method='pearson'), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb6a64",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### **H10.** Stores should sell more in the second half of the year.\n",
    "**False Hypothesis:** Stores sell less during the second half of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec415b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T20:44:04.884883Z",
     "start_time": "2023-06-06T20:44:04.201789Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['month','sales']].groupby( 'month' ).sum().reset_index()\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.barplot(x='month', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.regplot(x='month', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.heatmap(aux1.corr( method='pearson'), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede2e92e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### **H11.** Stores should sell more after the 10th day of each month.\n",
    "**True Hypothesis**: Stores sell more after the 10th day of each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faddde28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T20:44:05.810790Z",
     "start_time": "2023-06-06T20:44:04.886786Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['day','sales']].groupby( 'day' ).sum().reset_index()\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "sns.barplot(x='day', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.regplot(x='day', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "sns.heatmap(aux1.corr( method='pearson'), annot=True);\n",
    "\n",
    "aux1['before_after'] = aux1['day'].apply( lambda x: 'before_10_days' if x <= 10 else 'after_10_days' )\n",
    "aux2 = aux1[['before_after','sales']].groupby( 'before_after' ).sum().reset_index()\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "sns.barplot( x ='before_after', y='sales', data=aux2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc357e8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### **H12.**  Stores should sell less on weekends.\n",
    "**True Hypothesis**: Stores sell less on weekends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d714768",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T20:44:06.465784Z",
     "start_time": "2023-06-06T20:44:05.812787Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['day_of_week','sales']].groupby( 'day_of_week' ).sum().reset_index()\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.barplot(x='day_of_week', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.regplot(x='day_of_week', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.heatmap(aux1.corr( method='pearson'), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c8a468",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### **H13.** Stores should sell less during school holidays.\n",
    "**True Hypothesis**: Stores sell less during school holidays, except in the months of July and August."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da607442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T20:44:06.920922Z",
     "start_time": "2023-06-06T20:44:06.467785Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['school_holiday', 'sales']].groupby('school_holiday').sum().reset_index()\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "sns.barplot( x='school_holiday', y='sales', data=aux1);\n",
    "\n",
    "aux2 = df4[['month', 'school_holiday', 'sales']].groupby(['month', 'school_holiday']).sum().reset_index()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.barplot(x='month', y='sales', hue='school_holiday', data=aux2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7cfd17",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 4.3 Analise Multivariada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf6d53b",
   "metadata": {
    "hidden": true,
    "hide_input": false
   },
   "source": [
    "### 4.3.1 Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61350d7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T20:44:08.006794Z",
     "start_time": "2023-06-06T20:44:06.922790Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Only categorical data\n",
    "a = df4.select_dtypes( include='object')\n",
    "\n",
    "# Calculate cramer v\n",
    "a1 = cramer_v( a['state_holiday'], a['state_holiday'] )\n",
    "a2 = cramer_v( a['state_holiday'], a['store_type'] )\n",
    "a3 = cramer_v( a['state_holiday'], a['assortment'] )\n",
    "\n",
    "a4 = cramer_v( a['store_type'], a['state_holiday'] )\n",
    "a5 = cramer_v( a['store_type'], a['store_type'] )\n",
    "a6 = cramer_v( a['store_type'], a['assortment'] )\n",
    "\n",
    "a7 = cramer_v( a['assortment'], a['state_holiday'] )\n",
    "a8 = cramer_v( a['assortment'], a['store_type'] )\n",
    "a9 = cramer_v( a['assortment'], a['assortment'] )\n",
    "\n",
    "# Final DataSet\n",
    "\n",
    "d = pd.DataFrame( {'state_holiday': [a1, a2, a3],\n",
    "                   'store_type':    [a4, a5, a6],\n",
    "                   'assortment':    [a7, a8, a9]  })\n",
    "\n",
    "d = d.set_index( d.columns )\n",
    "\n",
    "# Heatmap\n",
    "sns.heatmap( d, annot=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8139b0",
   "metadata": {},
   "source": [
    "# 5.0 STEP 5 - DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b5e6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:00:29.026754Z",
     "start_time": "2023-06-12T19:00:28.982014Z"
    }
   },
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44849f7d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 5.1 - Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746c6f12",
   "metadata": {},
   "source": [
    "## 5.2 - Reescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad0d301",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:00:38.241527Z",
     "start_time": "2023-06-12T19:00:38.116808Z"
    }
   },
   "outputs": [],
   "source": [
    "rs = RobustScaler()\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "# Year\n",
    "df5['year'] = mms.fit_transform( df5[['year']].values )\n",
    "#pickle.dump( rs, open( 'C:/Users/perot/Documents/ds_repos/projects/Rossmann_Sales_Prediction/rossmann_prediction/parameters/year_scaler.pkl', 'wb') )\n",
    "\n",
    "# competition distance\n",
    "df5['competition_distance'] = rs.fit_transform( df5[['competition_distance']].values )\n",
    "#pickle.dump( rs, open( 'C:/Users/perot/Documents/ds_repos/projects/Rossmann_Sales_Prediction/rossmann_prediction/parameters/competition_distance_scaler.pkl', 'wb') )\n",
    "\n",
    "# competition time month\n",
    "df5['competition_time_month'] = rs.fit_transform( df5[['competition_time_month']].values )\n",
    "#pickle.dump( rs, open( 'C:/Users/perot/Documents/ds_repos/projects/Rossmann_Sales_Prediction/rossmann_prediction/parameters/competition_time_month_scaler.pkl', 'wb') )\n",
    "\n",
    "# promo time week\n",
    "df5['promo_time_week'] = mms.fit_transform( df5[['promo_time_week']].values )\n",
    "#pickle.dump( rs, open( 'C:/Users/perot/Documents/ds_repos/projects/Rossmann_Sales_Prediction/rossmann_prediction/parameters/promo_time_week_scaler.pkl', 'wb') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b5671f",
   "metadata": {},
   "source": [
    "## 5.3 - Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cbd7c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:00:42.962649Z",
     "start_time": "2023-06-12T19:00:38.580429Z"
    }
   },
   "outputs": [],
   "source": [
    "# day of week\n",
    "df5['day_of_week_sin'] = df5['day_of_week'].apply( lambda x: np.sin( x * ( 2. * np.pi/7 ) ) )\n",
    "df5['day_of_week_cos'] = df5['day_of_week'].apply( lambda x: np.sin( x * ( 2. * np.pi/7 ) ) )\n",
    "\n",
    "# month\n",
    "df5['month_sin'] = df5['month'].apply( lambda x: np.sin( x * ( 2. * np.pi/12 ) ) )\n",
    "df5['month_cos'] = df5['month'].apply( lambda x: np.sin( x * ( 2. * np.pi/12 ) ) )\n",
    "\n",
    "# day\n",
    "df5['day_sin'] = df5['day'].apply( lambda x: np.sin( x * ( 2. * np.pi/30 ) ) )\n",
    "df5['day_cos'] = df5['day'].apply( lambda x: np.sin( x * ( 2. * np.pi/30 ) ) )\n",
    "\n",
    "# week of year\n",
    "df5['week_of_year_sin'] = df5['week_of_year'].apply( lambda x: np.sin( x * ( 2. * np.pi/52 ) ) )\n",
    "df5['week_of_year_cos'] = df5['week_of_year'].apply( lambda x: np.sin( x * ( 2. * np.pi/52 ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047a26df",
   "metadata": {},
   "source": [
    "### 5.3.1 - Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a8482",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:00:43.307519Z",
     "start_time": "2023-06-12T19:00:42.965646Z"
    }
   },
   "outputs": [],
   "source": [
    "# state_holiday - Hot Encoding\n",
    "df5 = pd.get_dummies( df5, prefix=['state_holiday'], columns=['state_holiday'] )\n",
    "\n",
    "# store_type - Label Encoding\n",
    "le = LabelEncoder()\n",
    "df5['store_type'] = le.fit_transform( df5['store_type'] )\n",
    "#pickle.dump(le, open('C:/Users/perot/Documents/ds_repos/projects/Rossmann_Sales_Prediction/rossmann_prediction/parameters/store_type_scaler.pkl', 'wb'))\n",
    "\n",
    "# assortment - Ordinal Encoding\n",
    "assortment_dict={'basic':1, 'extra':2, 'extended':3 }\n",
    "df5['assortment'] = df5['assortment'].map( assortment_dict )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d673f7c",
   "metadata": {},
   "source": [
    "## 5.4 - Aplying Data Preparation on train, test and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928b54ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:10:32.517300Z",
     "start_time": "2023-06-12T19:10:32.423392Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenation of features + variable response prior to apply data prepararion on validation and test datasets.\n",
    "training_df = pd.concat([x_train, y_train], axis=1)\n",
    "validation_df = pd.concat([x_valid, y_valid], axis=1)\n",
    "test_df = pd.concat([x_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2921d9d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:11:33.387446Z",
     "start_time": "2023-06-12T19:10:34.486496Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying data preparation on validation and test datasets\n",
    "x_train_prep = data_preparation(training_df)\n",
    "x_valid_prep = data_preparation(validation_df)\n",
    "x_test_prep = data_preparation(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76706703",
   "metadata": {},
   "source": [
    "### 5.4.1 - Creation of Training, Validation and Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16310894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:11:33.449321Z",
     "start_time": "2023-06-12T19:11:33.389427Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = x_train_prep.drop('sales', axis=1)\n",
    "Y_train = x_train_prep['sales']\n",
    "X_valid = x_valid_prep.drop('sales', axis=1)\n",
    "Y_valid = x_valid_prep['sales']\n",
    "X_test = x_test_prep.drop('sales', axis=1)\n",
    "Y_test = x_test_prep['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54a8d18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:11:33.465315Z",
     "start_time": "2023-06-12T19:11:33.452304Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\" X_train:{X_train.shape}\\n Y_train:{Y_train.shape}\\n X_valid:{X_valid.shape}\\n Y_valid:{Y_valid.shape}\\n X_test{X_test.shape}\\n Y_test{Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ed1707",
   "metadata": {},
   "source": [
    "# 6.0 STEP 6 - FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4986889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of Datasets for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9234fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T20:45:23.640345Z",
     "start_time": "2023-06-06T20:45:23.579153Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_fs = X_train.drop('date', axis=1).copy()\n",
    "y_train_fs = Y_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d705b8",
   "metadata": {},
   "source": [
    "## 6.2 - Boruta as Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d062f0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T21:31:34.663943Z",
     "start_time": "2023-06-06T20:45:28.069679Z"
    }
   },
   "outputs": [],
   "source": [
    "# training and test dataset for Boruta\n",
    "x_train_n = x_train_fs.values\n",
    "y_train_n = y_train_fs.values.ravel()\n",
    "\n",
    "# Define RandomForest Regressor\n",
    "rf = RandomForestRegressor( n_jobs=-1 )\n",
    "\n",
    "#  Define Boruta\n",
    "boruta = BorutaPy( rf, n_estimators='auto', verbose=2, random_state=42 ).fit( x_train_n, y_train_n )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e904d01",
   "metadata": {},
   "source": [
    "### 6.2.1 - Best features from Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85249704",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T21:31:34.710855Z",
     "start_time": "2023-06-06T21:31:34.665818Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "cols_selected = boruta.support_.tolist()\n",
    "\n",
    "# Best Features\n",
    "cols_selected_boruta = x_train_fs.iloc[:, cols_selected].columns.to_list()\n",
    "\n",
    "cols_not_selected_boruta = list(np.setdiff1d(x_train_fs.columns, cols_selected_boruta ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927af55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T21:31:34.725900Z",
     "start_time": "2023-06-06T21:31:34.712982Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "cols_selected_boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e52c6fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:01:47.610942Z",
     "start_time": "2023-06-12T19:01:47.597115Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_not_selected_boruta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcc0ccc",
   "metadata": {},
   "source": [
    "## 6.3 - Manual Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803bec30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:18:19.458542Z",
     "start_time": "2023-06-12T19:18:19.439839Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_selected_boruta = [\n",
    " 'store',\n",
    " 'promo',\n",
    " 'month_cos',\n",
    " 'month_sin',\n",
    " 'store_type',\n",
    " 'assortment',\n",
    " 'competition_distance',\n",
    " 'competition_open_since_month',\n",
    " 'competition_open_since_year',\n",
    " 'promo2',\n",
    " 'promo2_since_week',\n",
    " 'promo2_since_year',\n",
    " 'competition_time_month',\n",
    " 'promo_time_week',\n",
    " 'day_of_week_sin',\n",
    " 'day_of_week_cos',\n",
    " 'week_of_year_cos',\n",
    " 'week_of_year_sin',   \n",
    " 'day_sin',\n",
    " 'day_cos']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5746bcea",
   "metadata": {},
   "source": [
    "# 7.0 STEP 7 - ML MODEL'S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310eced7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T21:31:34.773347Z",
     "start_time": "2023-06-06T21:31:34.759957Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset to be used for ML Cross-Validation training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf07098",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:18:25.109388Z",
     "start_time": "2023-06-12T19:18:24.951049Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cv = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f0f91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:19:23.934412Z",
     "start_time": "2023-06-12T19:18:25.716840Z"
    }
   },
   "outputs": [],
   "source": [
    "training_cv = data_preparation(df_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017af1d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:19:23.949984Z",
     "start_time": "2023-06-12T19:19:23.936395Z"
    }
   },
   "outputs": [],
   "source": [
    "training_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5547d6f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:19:23.965390Z",
     "start_time": "2023-06-12T19:19:23.951983Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset to be used for ML regular training and Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeab976",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:19:24.058692Z",
     "start_time": "2023-06-12T19:19:23.967326Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_reg = X_train.drop('date', axis=1).copy()\n",
    "X_test_reg = X_test.drop('date', axis=1).copy()\n",
    "X_valid_reg = X_valid.drop('date', axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de97255",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:19:24.073707Z",
     "start_time": "2023-06-12T19:19:24.059705Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_reg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1144450",
   "metadata": {},
   "source": [
    "## 7.1 - Average Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72140565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T21:32:35.665710Z",
     "start_time": "2023-06-06T21:32:35.588408Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "aux1 = pd.concat([X_valid, Y_valid], axis=1)\n",
    "\n",
    "# Predictions\n",
    "aux2 = aux1[['store', 'sales']].groupby('store').mean().reset_index().rename( columns={'sales': 'predictions'} )\n",
    "aux1 = pd.merge( aux1, aux2, how='left', on='store' )\n",
    "yhat_baseline= aux1['predictions']\n",
    "\n",
    "# Performance\n",
    "baseline_result = ml_error( 'Average Model', ( Y_valid ), ( yhat_baseline ) )\n",
    "baseline_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a698bfd6",
   "metadata": {},
   "source": [
    "## 7.2 - Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8a9f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T21:32:36.103008Z",
     "start_time": "2023-06-06T21:32:35.667706Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "lr = LinearRegression().fit( X_train_reg, Y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_lr = lr.predict( X_valid_reg )\n",
    "\n",
    "# performance\n",
    "lr_result = ml_error( 'Linear Regression', ( Y_valid ), ( yhat_lr ) )\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75758454",
   "metadata": {},
   "source": [
    "### 7.2.1 - Linear Regression Model: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e36e66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T21:32:39.007118Z",
     "start_time": "2023-06-06T21:32:36.104989Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "lr_result_cv = cross_validation( training_cv, 5, 'Linear Regression', lr, verbose=False )\n",
    "lr_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c2a7c0",
   "metadata": {},
   "source": [
    "## 7.3 - Linear Regression Regularized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a978b2ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T21:32:48.575420Z",
     "start_time": "2023-06-06T21:32:39.009024Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "lrr = Lasso( alpha=0.01 ).fit( X_train_reg, Y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_lrr = lrr.predict( X_valid_reg )\n",
    "\n",
    "# performance\n",
    "lrr_result = ml_error( 'Linear Regression - Lasso', ( Y_valid ), ( yhat_lrr ) )\n",
    "lrr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e937f82",
   "metadata": {},
   "source": [
    "### 7.3.1 - Linear Regression Regularized Model - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c3123",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T21:33:44.199025Z",
     "start_time": "2023-06-06T21:32:48.577419Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "lrr_result_cv = cross_validation( training_cv , 5, 'Lasso', lrr, verbose=False )\n",
    "lrr_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168deacc",
   "metadata": {},
   "source": [
    "## 7.4 - Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55fb9ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T21:34:27.438133Z",
     "start_time": "2023-06-06T21:33:44.200988Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# model definition\n",
    "rf = RandomForestRegressor( n_estimators=100, n_jobs=-1, random_state=42 ).fit( X_train_reg, Y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_rf = rf.predict( X_valid_reg )\n",
    "\n",
    "# performance\n",
    "rf_result = ml_error( 'Random Forest Regressor', ( Y_valid ), ( yhat_rf ) )\n",
    "rf_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975acf79",
   "metadata": {},
   "source": [
    "### 7.4.1 - Randon Forest Regresson - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2367b725",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T21:38:16.325851Z",
     "start_time": "2023-06-06T21:34:27.440408Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "rf_result_cv = cross_validation( training_cv, 5, 'Randon Forest Regressor', rf, verbose=True )\n",
    "rf_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489c83a6",
   "metadata": {},
   "source": [
    "## 7.5 - XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040cb0fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T21:38:36.211558Z",
     "start_time": "2023-06-06T21:38:16.327850Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model_xgb = xgb.XGBRegressor( objective='reg:squarederror',\n",
    "                              n_estimators=100,\n",
    "                              eta=0.01,\n",
    "                              max_depth=10,\n",
    "                              subsample=0.7,\n",
    "                              colsample_bytree=0.9 ).fit( X_train_reg, Y_train )                      \n",
    "\n",
    "# prediction\n",
    "yhat_xgb = model_xgb.predict( X_valid_reg)\n",
    "\n",
    "# performance\n",
    "xgb_result = ml_error( 'XGBoost Regressor', ( Y_valid ), ( yhat_xgb ) )\n",
    "xgb_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e698ca4",
   "metadata": {},
   "source": [
    "### 7.5.1 - XGBoost Regressor - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cad677",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T21:40:20.177259Z",
     "start_time": "2023-06-06T21:38:36.213558Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "xgb_result_cv = cross_validation( training_cv, 5, 'XGboost Regressor', model_xgb, verbose=True )\n",
    "xgb_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4df355",
   "metadata": {},
   "source": [
    "## 7.6 - Compare Model's Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540bf40a",
   "metadata": {},
   "source": [
    "### 7.6.1 - Single Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1357c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T21:40:20.192497Z",
     "start_time": "2023-06-06T21:40:20.179258Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "modelling_result = pd.concat( [baseline_result, lr_result, lrr_result, rf_result, xgb_result] )\n",
    "modelling_result.sort_values( 'RMSE' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dfcb96",
   "metadata": {},
   "source": [
    "### 7.6.2 - Real Performance: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a89ecc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T21:40:20.224008Z",
     "start_time": "2023-06-06T21:40:20.194004Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "modelling_result_cv = pd.concat( [lr_result_cv, lrr_result_cv, rf_result_cv, xgb_result_cv] )\n",
    "modelling_result_cv.sort_values('RMSE CV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffa65d4",
   "metadata": {},
   "source": [
    "# 8.0 STEP 8 - HYPERPARAMETER FINE TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4da50",
   "metadata": {},
   "source": [
    "## 8.1 - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f886fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:19:46.857107Z",
     "start_time": "2023-06-12T19:19:46.845455Z"
    }
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "     'n_estimators': [100,350,550,850,1000], \n",
    "     'eta': [0.01, 0.03],\n",
    "     'max_depth': [5, 9, 13, 17, 20],\n",
    "     'subsample': [0.1, 0.5, 0.7],\n",
    "     'colsample_bytree': [0.3, 0.7, 0.9],\n",
    "     'min_child_weight':[3, 8, 15] }\n",
    "\n",
    "MAX_EVAL = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972c3ff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T21:40:20.588114Z",
     "start_time": "2023-06-06T21:40:20.242034Z"
    }
   },
   "outputs": [],
   "source": [
    "final_result = pd.DataFrame()\n",
    "\n",
    "for i in range( MAX_EVAL ):\n",
    "    # choose values for parameters randomly\n",
    "    hp = { k: random.sample(v, 1)[0] for k, v in param.items() }\n",
    "    print( hp )\n",
    "    \n",
    "    # model\n",
    "    model_xgb = xgb.XGBRegressor( objective='reg:squarederror',\n",
    "                                  n_estimators=hp['n_estimators'],\n",
    "                                  eta=hp['eta'],\n",
    "                                  max_depth=hp['max_depth'],\n",
    "                                  subsample=hp['subsample'],\n",
    "                                  colsample_bytree=hp['colsample_bytree'],\n",
    "                                  min_child_weight=hp['min_child_weight'] )\n",
    "\n",
    "    # performance\n",
    "    result = cross_validation( training_cv, 5, 'XGBoost Regressor', model_xgb, verbose=True )\n",
    "    final_result = pd.concat( [final_result, result] )\n",
    "\n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741122ee",
   "metadata": {},
   "source": [
    "## 8.2 - Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f7da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:19:54.603426Z",
     "start_time": "2023-06-12T19:19:54.585392Z"
    }
   },
   "outputs": [],
   "source": [
    "param_tuned = {\n",
    "    'n_estimators':100, \n",
    "    'eta':0.03,\n",
    "    'max_depth':9,\n",
    "    'subsample':0.1,\n",
    "    'colsample_bytree':0.3,\n",
    "    'min_child_weight':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50807a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:19:57.040126Z",
     "start_time": "2023-06-12T19:19:56.917654Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "aux1 = pd.concat([X_train_reg, Y_train], axis=1)\n",
    "aux2 = pd.concat([X_valid_reg, Y_valid], axis=1)\n",
    "training_final = pd.concat([aux1, aux2], axis=0)\n",
    "x_training_final = training_final.drop('sales', axis=1)\n",
    "y_trianing_final = training_final['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22cb25e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:23:53.716621Z",
     "start_time": "2023-06-12T19:23:40.746417Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "model_xgb_tuned = xgb.XGBRegressor( objective='reg:squarederror',\n",
    "                                    n_estimators=param_tuned['n_estimators'],\n",
    "                                    eta=param_tuned['eta'],\n",
    "                                    max_depth=param_tuned['max_depth'],\n",
    "                                    subsample=param_tuned['subsample'],\n",
    "                                    colsample_bytree=param_tuned['colsample_bytree'],\n",
    "                                    min_child_weight=param_tuned['min_child_weight'] )\n",
    "# Model Training\n",
    "model_xgb_tuned.fit(x_training_final, y_trianing_final)\n",
    "\n",
    "# prediction\n",
    "yhat_xgb_tuned = model_xgb_tuned.predict( X_test_reg )\n",
    "\n",
    "# performance           \n",
    "xgb_result_tuned = ml_error( 'XGBoost Regressor', ( Y_test), ( yhat_xgb_tuned ) )\n",
    "xgb_result_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee41a416",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:23:59.686697Z",
     "start_time": "2023-06-12T19:23:59.677700Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mpe = mean_percentage_error( (Y_test), (yhat_xgb_tuned) )\n",
    "mpe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e58156",
   "metadata": {},
   "source": [
    "# 9.0 STEP 9 - EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc900d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:27:46.001833Z",
     "start_time": "2023-06-12T19:27:45.986805Z"
    }
   },
   "outputs": [],
   "source": [
    "df9 = x_test_prep.copy()\n",
    "\n",
    "# rescale\n",
    "df9['sales'] = ( df9['sales'] )\n",
    "df9['predictions'] = ( yhat_xgb_tuned )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f14516e",
   "metadata": {},
   "source": [
    "## 9.1 - Business Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba70f81b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:27:47.470525Z",
     "start_time": "2023-06-12T19:27:46.917129Z"
    }
   },
   "outputs": [],
   "source": [
    "# sum of predictions\n",
    "df91 = df9[['store', 'predictions']].groupby( 'store' ).sum().reset_index()\n",
    "\n",
    "# MAE and MAPE\n",
    "df9_aux1 = df9[['store','sales','predictions']].groupby( 'store' ).apply( lambda x: mean_absolute_error( x['sales'], x['predictions'] ) ).reset_index().rename( columns={0:'MAE'} )\n",
    "df9_aux2 = df9[['store','sales','predictions']].groupby( 'store' ).apply( lambda x: mean_absolute_percentage_error( x['sales'], x['predictions'] ) ).reset_index().rename( columns={0:'MAPE'} )\n",
    "\n",
    "# Merge\n",
    "df9_aux3 = pd.merge( df9_aux1, df9_aux2, how='inner', on='store')\n",
    "df92 = pd.merge( df91, df9_aux3, how='inner', on='store')\n",
    "\n",
    "# Scenarios\n",
    "df92['worst_scenario'] = df92['predictions'] - df92['MAE']\n",
    "df92['best_scenario'] = df92['predictions'] + df92['MAE']\n",
    "\n",
    "# order columns\n",
    "df92 = df92[['store','predictions','worst_scenario','best_scenario','MAE','MAPE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a98e47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:27:49.437172Z",
     "start_time": "2023-06-12T19:27:49.420780Z"
    }
   },
   "outputs": [],
   "source": [
    "df92.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7584349f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:27:53.430600Z",
     "start_time": "2023-06-12T19:27:53.417675Z"
    }
   },
   "outputs": [],
   "source": [
    "df92.sort_values( 'MAPE', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57853b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:27:54.676058Z",
     "start_time": "2023-06-12T19:27:54.505598Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot( x='store', y='MAPE', data=df92)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b570af",
   "metadata": {},
   "source": [
    "## 9.2 - Total Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c53e7e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:28:00.542588Z",
     "start_time": "2023-06-12T19:28:00.521588Z"
    }
   },
   "outputs": [],
   "source": [
    "df93 = df92[['predictions','worst_scenario','best_scenario']].apply( lambda x: np.sum( x ), axis=0 ).reset_index().rename( columns={'index': 'Scenario', 0: 'Values'})\n",
    "\n",
    "df93['Values'] = df93['Values'].map( 'R${:,.2f}'.format )\n",
    "df93"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d5e5bb",
   "metadata": {},
   "source": [
    "## 9.3 - ML Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bdd9c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:28:04.272428Z",
     "start_time": "2023-06-12T19:28:04.264053Z"
    }
   },
   "outputs": [],
   "source": [
    "df9['error'] = df9['sales'] - df9['predictions']\n",
    "df9['error_rate'] = df9['predictions'] / df9['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe898d34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:28:46.905249Z",
     "start_time": "2023-06-12T19:28:06.763430Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot( 2, 2, 1 )\n",
    "sns.lineplot( x='date', y='sales', data=df9, label='SALES')\n",
    "sns.lineplot( x='date', y='predictions', data=df9, label='PREDICTIONS')\n",
    "\n",
    "plt.subplot( 2, 2, 2 )\n",
    "sns.lineplot( x='date', y='error_rate', data=df9)\n",
    "plt.axhline(1, linestyle='--')\n",
    "\n",
    "plt.subplot( 2, 2, 3 )\n",
    "sns.distplot( df9['error'] )\n",
    "\n",
    "plt.subplot( 2, 2, 4 )\n",
    "sns.scatterplot( df9['predictions'], df9['error'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a973e",
   "metadata": {},
   "source": [
    "# 10.0 STEP 10 - DEPLOY MODEL TO PRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01483b24",
   "metadata": {},
   "source": [
    "## 10.1 - Rossmann Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269e9dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T23:26:01.797368Z",
     "start_time": "2023-01-04T23:26:01.773291Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import pickle\n",
    "import datetime\n",
    "import inflection\n",
    "import pandas   as pd\n",
    "import numpy    as np\n",
    "\n",
    "class Rossmann( object ):\n",
    "    def __init__( self ):\n",
    "        self.home_path                     = 'C:/Users/perot/Documents/ds_repos/projects/Rossmann_Sales_Prediction/rossmann_prediction'\n",
    "        self.competition_time_month_scaler = pickle.load( open( self.home_path + '/parameters/competition_time_month_scaler.pkl', 'rb') )\n",
    "        self.competition_distance_scaler   = pickle.load( open( self.home_path + '/parameters/competition_distance_scaler.pkl', 'rb') )\n",
    "        self.promo_time_week_scaler        = pickle.load( open( self.home_path + '/parameters/promo_time_week_scaler.pkl', 'rb') )\n",
    "        self.store_type_scaler             = pickle.load( open( self.home_path + '/parameters/store_type_scaler.pkl', 'rb'))\n",
    "        self.year_scaler                   = pickle.load( open( self.home_path + '/parameters/year_scaler.pkl', 'rb') )\n",
    "              \n",
    "    def data_cleaning( self, df1 ):\n",
    " \n",
    "        ## rename Columns\n",
    "        cols_old = ['Store', 'DayOfWeek', 'Date', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'StoreType',\n",
    "                        'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2',\n",
    "                        'Promo2SinceWeek','Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "        snakecase = lambda x: inflection.underscore( x )\n",
    "\n",
    "        cols_new = list( map( snakecase, cols_old ) )\n",
    "\n",
    "        # rename\n",
    "        df1.columns = cols_new\n",
    "\n",
    "        # data types\n",
    "        df1['date'] = pd.to_datetime (df1['date'] )\n",
    "\n",
    "        # fillout NA\n",
    "\n",
    "        # Competition Distance\n",
    "        df1['competition_distance'] = df1['competition_distance'].apply( lambda x: 200000.0 if math.isnan( x ) else x )\n",
    "\n",
    "        # Competition Open Since Month\n",
    "        df1['competition_open_since_month'] = df1.apply( lambda x: x['date'].month if math.isnan( x['competition_open_since_month'] ) else x['competition_open_since_month'], axis=1 )\n",
    "\n",
    "        # Competition Open Since Year\n",
    "        df1['competition_open_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['competition_open_since_year'] ) else x['competition_open_since_year'], axis=1 )\n",
    "\n",
    "        # Promo2 Since Week\n",
    "        df1['promo2_since_week'] = df1.apply( lambda x: x['date'].week if math.isnan( x['promo2_since_week'] ) else x['promo2_since_week'], axis=1 )\n",
    "\n",
    "        # Promo2 Since Year\n",
    "        df1['promo2_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['promo2_since_year'] ) else x['promo2_since_year'], axis=1 )\n",
    "\n",
    "        # Promo Interval\n",
    "        month_map = {1: 'Jan', 2: 'Fev', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sept', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "\n",
    "        df1['promo_interval'].fillna(0, inplace=True)\n",
    "\n",
    "        df1['month_map'] = df1['date'].dt.month.map( month_map )\n",
    "\n",
    "        df1['is_promo'] = df1[['promo_interval', 'month_map']].apply( lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split( ',' ) else 0, axis=1 )\n",
    "\n",
    "        # change data types\n",
    "\n",
    "        # competition\n",
    "        df1['competition_open_since_month'] = df1['competition_open_since_month'].astype( int )\n",
    "        df1['competition_open_since_year'] = df1['competition_open_since_year'].astype( int )\n",
    "\n",
    "        # promo2\n",
    "        df1['promo2_since_week'] = df1['promo2_since_week'].astype( int )\n",
    "        df1['promo2_since_year'] = df1['promo2_since_year'].astype( int )\n",
    "\n",
    "        return df1\n",
    "    \n",
    "    def feature_engineering( self, df2 ):\n",
    "        \n",
    "        # year\n",
    "        df2['year'] = df2['date'].dt.year\n",
    "\n",
    "        # month\n",
    "        df2['month'] = df2['date'].dt.month\n",
    "\n",
    "        # day\n",
    "        df2['day'] = df2['date'].dt.day\n",
    "\n",
    "        # week of year\n",
    "        df2['week_of_year'] = df2['date'].dt.weekofyear\n",
    "\n",
    "        # year week\n",
    "        df2['year_week'] = df2['date'].dt.strftime( '%Y-%W' )\n",
    "\n",
    "        # competition since\n",
    "        df2['competition_since'] = df2.apply( lambda x: datetime.datetime( year=x['competition_open_since_year'], month=x['competition_open_since_month'], day=1 ), axis=1 )\n",
    "        df2['competition_time_month'] = ( ( df2['date'] - df2['competition_since'] ) / 30 ).apply( lambda x: x.days ).astype( int )                                                                                      \n",
    "\n",
    "        # promo since\n",
    "        df2['promo_since'] = df2['promo2_since_year'].astype( str ) + '-' + df2['promo2_since_week'].astype( str )\n",
    "        df2['promo_since'] = df2['promo_since'].apply( lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
    "        df2['promo_time_week'] = ( ( df2['date'] - df2['promo_since'] ) /7 ).apply( lambda x: x.days ).astype( int )\n",
    "\n",
    "        # assortment\n",
    "        df2['assortment'] = df2['assortment'].apply(lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended' )\n",
    "\n",
    "        # state holiday\n",
    "        df2['state_holiday'] = df2['state_holiday'].apply( lambda x:'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day' )    \n",
    "\n",
    "        # rows filtering\n",
    "        df2 = df2[df2['open'] != 0]\n",
    "\n",
    "        # cols selection\n",
    "        cols_drop = ['open', 'promo_interval', 'month_map']\n",
    "        df2 = df2.drop( cols_drop, axis = 1)\n",
    "\n",
    "        return df2\n",
    "\n",
    "    def data_preparation( self, df5 ):\n",
    "\n",
    "        # 5.2 - Rescaling\n",
    "\n",
    "        # competition distance\n",
    "        df5['competition_distance'] = self.competition_distance_scaler.transform( df5[['competition_distance']].values )\n",
    "\n",
    "        # Year\n",
    "        df5['year'] = self.year_scaler.transform( df5[['year']].values )\n",
    "\n",
    "        # competition time month\n",
    "        df5['competition_time_month'] = self.competition_time_month_scaler.transform( df5[['competition_time_month']].values )\n",
    "\n",
    "        # promo time week\n",
    "        df5['promo_time_week'] = self.promo_time_week_scaler.transform( df5[['promo_time_week']].values )\n",
    "\n",
    "        ### 5.3.1 - Encoding\n",
    "        \n",
    "        # state_holiday - Hot Encoding\n",
    "        df5 = pd.get_dummies( df5, prefix=['state_holiday'], columns=['state_holiday'] )\n",
    "\n",
    "        # store_type - Label Encoding\n",
    "        df5['store_type'] = self.store_type_scaler.fit_transform( df5['store_type'] )\n",
    "        \n",
    "        # assortment - Ordinal Encoding\n",
    "        assortment_dict={'basic':1, 'extra':2, 'extended':3 }\n",
    "        df5['assortment'] = df5['assortment'].map( assortment_dict )\n",
    "\n",
    "        ### 5.3.3 - Encoding\n",
    "\n",
    "        # day of week\n",
    "        df5['day_of_week_sin'] = df5['day_of_week'].apply( lambda x: np.sin( x * ( 2. * np.pi/7 ) ) )\n",
    "        df5['day_of_week_cos'] = df5['day_of_week'].apply( lambda x: np.sin( x * ( 2. * np.pi/7 ) ) )\n",
    "\n",
    "        # month\n",
    "        df5['month_sin'] = df5['month'].apply( lambda x: np.sin( x * ( 2. * np.pi/12 ) ) )\n",
    "        df5['month_cos'] = df5['month'].apply( lambda x: np.sin( x * ( 2. * np.pi/12 ) ) )\n",
    "\n",
    "        # day\n",
    "        df5['day_sin'] = df5['day'].apply( lambda x: np.sin( x * ( 2. * np.pi/30 ) ) )\n",
    "        df5['day_cos'] = df5['day'].apply( lambda x: np.sin( x * ( 2. * np.pi/30 ) ) )\n",
    "\n",
    "        # week of year\n",
    "        df5['week_of_year_sin'] = df5['week_of_year'].apply( lambda x: np.sin( x * ( 2. * np.pi/52 ) ) )\n",
    "        df5['week_of_year_cos'] = df5['week_of_year'].apply( lambda x: np.sin( x * ( 2. * np.pi/52 ) ) )\n",
    "        \n",
    "        cols_selected = ['store', 'promo', 'month_cos', 'month_sin', 'store_type', 'assortment', 'competition_distance', 'competition_open_since_month', 'competition_open_since_year', 'promo2', 'promo2_since_week',\n",
    "                         'promo2_since_year', 'competition_time_month', 'promo_time_week', 'day_of_week_sin', 'day_of_week_cos', 'week_of_year_cos', 'week_of_year_sin', 'day_sin', 'day_cos']\n",
    "        \n",
    "        return df5[ cols_selected ]\n",
    "    \n",
    "    def get_prediction (self, model, original_data, test_data ):\n",
    "        # prediction\n",
    "        pred = model.predict( test_data )\n",
    "        \n",
    "        # join pred into the original data\n",
    "        original_data['prediction'] = np.expm1( pred )\n",
    "        \n",
    "        return original_data.to_json( orient='records', date_format='iso' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848789a3",
   "metadata": {},
   "source": [
    "## 10.2 - API Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e192b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T23:26:28.982357Z",
     "start_time": "2023-01-04T23:26:03.161284Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from flask             import Flask, request, Response\n",
    "from rossmann.rossmann import Rossmann\n",
    "\n",
    "# loading model\n",
    "\n",
    "model = pickle.load( open( 'C:/Users/perot/Documents/ds_repos/projects/Rossmann_Sales_Prediction/rossmann_prediction/model/model_rossmann.pkl', 'rb' ) )\n",
    "\n",
    "# initialize API\n",
    "app = Flask( __name__ )\n",
    "\n",
    "@app.route( '/rossmann/predict', methods=['POST'] )\n",
    "\n",
    "def rossmann_predict():\n",
    "    test_json = request.get_json()\n",
    "    \n",
    "    if test_json: #there is data\n",
    "               \n",
    "        if isinstance( test_json, dict ): # unique example\n",
    "            test_raw = pd.DataFrame( test_json, index=[0] )\n",
    "    \n",
    "        else:\n",
    "            test_raw = pd.DataFrame( test_json, columns=test_json[0].keys() ) # multiple examples\n",
    "            \n",
    "        # Instantiate Rossmann Class\n",
    "        pipeline = Rossmann()\n",
    "        \n",
    "        # data cleaning\n",
    "        df1 = pipeline.data_cleaning( test_raw )\n",
    "        \n",
    "        # feature engineering\n",
    "        df2 = pipeline.feature_engeneering( df1 )\n",
    "                \n",
    "        # data preparation\n",
    "        df3 = pipeline.data_preparation( df2 )\n",
    "                \n",
    "        # prediction\n",
    "        df_response = pipeline.get_prediction( model, test_raw, df3 )\n",
    "        \n",
    "        return df_response\n",
    "        \n",
    "    else:\n",
    "        return Response( '{}', status=200, mimetype='application/json' )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run( '0.0.0.0' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757bfc0d",
   "metadata": {},
   "source": [
    "## 10.3 - API Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c6a19e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T22:51:41.347467Z",
     "start_time": "2023-01-05T22:51:41.307393Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading test dataset\n",
    "df10 = pd.read_csv( 'C:/Users/perot/Documents/ds_repos/projects/Rossmann_Sales_Prediction/data_csv/test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa7de80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T22:51:58.106656Z",
     "start_time": "2023-01-05T22:51:58.067672Z"
    }
   },
   "outputs": [],
   "source": [
    "# merge test dataset + store\n",
    "df_test = pd.merge( df10, df_store_raw, how='left', on='Store' )\n",
    "\n",
    "# choose store for prediction\n",
    "df_test = df_test[df_test['Store'] == 22]\n",
    "\n",
    "# remove closed days\n",
    "df_test = df_test[df_test['Open'] != 0]\n",
    "df_test = df_test[~df_test['Open'].isnull() ]\n",
    "df_test = df_test.drop( 'Id', axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac48f18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T22:51:58.744726Z",
     "start_time": "2023-01-05T22:51:58.731725Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert dataframe to json\n",
    "data = json.dumps( df_test.to_dict( orient='records' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42102a8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T23:39:01.622999Z",
     "start_time": "2023-01-05T23:39:00.731988Z"
    }
   },
   "outputs": [],
   "source": [
    "# API Call\n",
    "url = 'https://rossmann-api-1osh.onrender.com/rossmann/predict'\n",
    "header = {'Content-type': 'application/json'}\n",
    "data = data\n",
    "\n",
    "r = requests.post( url, data=data , headers=header )\n",
    "print( 'Stadus Code{}'.format( r.status_code ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3dc38e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T23:39:01.638535Z",
     "start_time": "2023-01-05T23:39:01.627537Z"
    }
   },
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame( r.json(), columns=r.json()[0].keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6fc40b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T23:39:01.764480Z",
     "start_time": "2023-01-05T23:39:01.747756Z"
    }
   },
   "outputs": [],
   "source": [
    "d2 = d1[['store','prediction']].groupby( 'store' ).sum().reset_index()\n",
    "\n",
    "for i in range( len( d2 ) ):\n",
    "    print( 'Store number {} will sell R${:,.2f} in the next six weeks.'.format(d2.loc[i, 'store'], d2.loc[i, 'prediction'] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79d4ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T23:39:02.884946Z",
     "start_time": "2023-01-05T23:39:02.849933Z"
    }
   },
   "outputs": [],
   "source": [
    "d1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d067e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95848b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9fc918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc54bfdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1124884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
